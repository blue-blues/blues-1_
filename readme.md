# to do

1 . using new flash atttention model 3.0 from git

2. implemnation of deepspeed
   
3. creating an new dataset for indian

4. traning an tokenzier custom - (optional)
   
5. creating an new translation transformer for the translation
   
7. traning to create an good pretrain model


# completed!
1. just flash attention with working model - 5/11/24
